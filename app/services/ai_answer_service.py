import os
import fitz
import re
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions

from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from openai.error import RateLimitError, AuthenticationError

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ì„¤ì •
MODEL_NAME = "all-MiniLM-L6-v2"
COLLECTION_NAME = "faq_collection_pdf"
PDF_PATH = os.path.join(os.path.dirname(__file__), "data/usim.pdf")

# ì´ˆê¸°í™”
sbert_model = SentenceTransformer(MODEL_NAME)
chroma_client = chromadb.Client(Settings(anonymized_telemetry=False))
llm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo")

# ì§ˆë¬¸ ì¬ì‘ì„± í”„ë¡¬í”„íŠ¸
rewrite_prompt = PromptTemplate.from_template("""
ë„ˆëŠ” SKT ê³ ê°ì„¼í„°ì˜ FAQ ì§ˆë¬¸ ìƒì„± ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.

ê³ ê°ì´ ì…ë ¥í•œ ë¬¸ì¥ì€ í†µí™” ë˜ëŠ” ìì—°ì–´ ë¬¸ì¥ í˜•ì‹ì´ì•¼.
ë‚´ìš©ì´ USIM ë˜ëŠ” eSIMê³¼ ê´€ë ¨ëœ ê²½ìš°, ê·¸ ì§ˆë¬¸ì„ ê³µì‹ FAQ ìŠ¤íƒ€ì¼ë¡œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ì¤˜.
- ì„¤ëª…ì´ë‚˜ ë°°ê²½ì€ ì œê±°í•˜ê³ 
- ì§ˆë¬¸ë§Œ ë‚¨ê¸°ê³ 
- ê°„ë‹¨í•œ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜í•´

ë§Œì•½ ì§ˆë¬¸ì´ USIMê³¼ ê´€ë ¨ì´ ì—†ë‹¤ë©´, ì•„ë˜ì²˜ëŸ¼ ë§í•´:
ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.

ì ˆëŒ€ë¡œ ë‹µë³€ì„ í•˜ì§€ ë§ê³ , ë°˜ë“œì‹œ ì§ˆë¬¸ í˜•íƒœë¡œ ëë‚´ì¤˜.

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_question}

[FAQ ì§ˆë¬¸]
""")
rewrite_chain = LLMChain(llm=llm, prompt=rewrite_prompt)

# ìƒë‹´ì‚¬ ë§íˆ¬ë¡œ í¬ì¥í•˜ëŠ” í”„ë¡¬í”„íŠ¸
wrap_prompt = PromptTemplate.from_template("""
ë„ˆëŠ” SKT ê³ ê°ì„¼í„°ì˜ ìƒë‹´ì‚¬ì•¼.
ê³ ê°ì—ê²Œ ì•„ë˜ì˜ ë‚´ìš©ì„ ì •ì¤‘í•˜ê³  ì¹œì ˆí•œ ë§íˆ¬ë¡œ ì „ë‹¬í•´ì¤˜.
ë‚´ìš©ì€ ë°”ê¾¸ì§€ ë§ê³ , ë§íˆ¬ë§Œ ë¶€ë“œëŸ½ê³  ì¹œì ˆí•˜ê²Œ í¬ì¥í•´ì¤˜.

[ë‹µë³€ ì›ë¬¸]
{raw_answer}

[ìƒë‹´ì‚¬ ì‘ë‹µ]
""")
wrap_chain = LLMChain(llm=llm, prompt=wrap_prompt)

# PDF FAQ ì¶”ì¶œ
def extract_faq_from_pdf(pdf_path: str):
    print(f"[INFO] PDF ë¡œë”©: {pdf_path}")
    doc = fitz.open(pdf_path)
    text = "".join(page.get_text() for page in doc)
    pattern = r"Q\d+:\s*(.*?)\s*A:\s*(.*?)(?=\s*Q\d+:|\Z)"
    matches = re.findall(pattern, text, re.DOTALL)
    print(f"[INFO] ì¶”ì¶œëœ FAQ ìˆ˜: {len(matches)}")
    return [{"question": q.strip(), "answer": a.strip()} for q, a in matches]

# ë²¡í„°DB êµ¬ì„±
def prepare_vector_db():
    collection = chroma_client.get_or_create_collection(
        name=COLLECTION_NAME,
        embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(model_name=MODEL_NAME)
    )
    print("[INFO] ë²¡í„° ì»¬ë ‰ì…˜ í™•ë³´ ì™„ë£Œ")

    if collection.count() == 0:
        faq_data = extract_faq_from_pdf(PDF_PATH)
        ids = [f"faq_{i}" for i in range(len(faq_data))]
        docs = [f"{item['question']} {item['answer']}" for item in faq_data]
        collection.add(ids=ids, documents=docs, metadatas=faq_data)
        print(f"[INFO] ì´ {len(docs)}ê°œ FAQ ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ")
    else:
        print(f"[INFO] ê¸°ì¡´ FAQ ë¬¸ì„œ ìˆ˜: {collection.count()}")

    return collection

# ìœ ì‚¬ FAQ LLM ì„ íƒ
def search_faq_answer(user_query: str):
    collection = prepare_vector_db()
    results = collection.query(
        query_texts=[user_query],
        n_results=20,
        include=["metadatas"]
    )

    metadatas = results["metadatas"][0]
    if not metadatas:
        print("[WARN] FAQ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return False, "ê´€ë ¨ëœ FAQê°€ ì—†ìŠµë‹ˆë‹¤. ìƒë‹´ì‚¬ì—ê²Œ ì—°ê²°í•´ ë“œë¦´ê²Œìš”."

    faq_list_str = "\n".join([
        f"- ì§ˆë¬¸: {m['question']}\n  ë‹µë³€: {m['answer']}" for m in metadatas
    ])

    selection_prompt = PromptTemplate.from_template("""
ë„ˆëŠ” SKT ê³ ê°ì„¼í„° FAQ ì¶”ì²œ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ FAQ ì§ˆë¬¸/ë‹µë³€ ëª©ë¡ì´ì•¼.
ì‚¬ìš©ì ì§ˆë¬¸ì— ê°€ì¥ ì ì ˆí•œ FAQì˜ 'ë‹µë³€'ë§Œ ì¶œë ¥í•´ì¤˜. ì„¤ëª…ì€ í•˜ì§€ ë§ˆ.
ì •í™•íˆ ë§¤ì¹­ë˜ëŠ” ê²ƒì´ ì—†ìœ¼ë©´ "ê´€ë ¨ëœ FAQë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."ë¼ê³  ë§í•´ì¤˜.

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_question}

[í›„ë³´ FAQ ëª©ë¡]
{faq_list}

[ì„ íƒëœ ë‹µë³€]
""")
    selection_chain = LLMChain(llm=llm, prompt=selection_prompt)

    try:
        best_answer = selection_chain.invoke({
            "user_question": user_query,
            "faq_list": faq_list_str
        })["text"].strip()

        # ğŸ“Œ ë‹¤ì–‘í•œ ì‹¤íŒ¨ í‘œí˜„ íƒì§€
        FAILURE_INDICATORS = [
            "ê´€ë ¨ëœ FAQë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤",
            "FAQë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”",
            "ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤",
            "ë‹µë³€ì„ ì œê³µí•´ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            "ìƒë‹´ì‚¬ì—ê²Œ ì—°ê²°",
            "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤",
            "ì£„ì†¡í•©ë‹ˆë‹¤"
        ]

        if any(keyword in best_answer for keyword in FAILURE_INDICATORS) or len(best_answer) < 10:
            print("[INFO] LLMì´ ê´€ë ¨ FAQë¥¼ ì°¾ì§€ ëª»í–ˆë‹¤ê³  íŒë‹¨")
            return False, "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ìƒë‹´ì‚¬ì—ê²Œ ì—°ê²°í•´ ë“œë¦´ê²Œìš”."

        wrapped = wrap_chain.invoke({"raw_answer": best_answer})["text"].strip()
        return True, wrapped

    except Exception as e:
        print(f"[ERROR] LLM íŒë‹¨ ì˜¤ë¥˜: {str(e)}")
        return False, "FAQ íŒë‹¨ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


# ë©”ì¸ ì§ˆì˜ ì²˜ë¦¬
def ask_faq_agent(user_question: str):
    try:
        rewritten = rewrite_chain.invoke({"user_question": user_question})["text"].strip()
        print(f"[INFO] ì¬ì‘ì„±ëœ ì§ˆë¬¸: {rewritten}")
    except RateLimitError:
        return False, "í˜„ì¬ AI ì²˜ë¦¬ ìš”ì²­ì´ ë§ì•„ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
    except AuthenticationError:
        return False, "API ì¸ì¦ ì˜¤ë¥˜ì…ë‹ˆë‹¤. OpenAI í‚¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”."
    except Exception as e:
        return False, f"ì§ˆë¬¸ ì¬ì‘ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    if "ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤" in rewritten:
        print("[INFO] USIM ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨ë¨")
        return True, "ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤."

    return search_faq_answer(rewritten)

# ìµœìƒìœ„ ì§„ì…ì 
def get_gpt_response(user_question: str):
    is_valid, answer = ask_faq_agent(user_question)
    print(answer)
    print(is_valid)
    return is_valid, answer