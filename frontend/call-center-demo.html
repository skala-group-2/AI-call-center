<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>STT â†’ GPT â†’ TTS ë°ëª¨</title>
</head>
<body>
  <h1>ğŸ™ï¸ STT â†’ GPT â†’ TTS ë°ëª¨</h1>
  <button id="recordBtn">Start Recording</button>
  <p id="sttText">STT ë³€í™˜ëœ í…ìŠ¤íŠ¸ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</p>
  <p id="gptResponse" style="display: none;">GPT ì‘ë‹µì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</p>
  <p id="filteredText" style="display: none;">í•„í„°ë§ëœ ì§ˆë¬¸ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</p>
  <p id="summaryText" style="display: none;">ìš”ì•½ ë‚´ìš©ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</p>
  <audio id="ttsAudio" controls style="display: none;"></audio>

  <script>
    let isRecording = false;
    let mediaRecorder;
    let audioChunks = [];

    const btn = document.getElementById('recordBtn');
    const sttTextEl = document.getElementById('sttText');
    const gptResponseEl = document.getElementById('gptResponse');
    const filteredTextEl = document.getElementById('filteredText');
    const summaryTextEl = document.getElementById('summaryText');
    const ttsAudioEl = document.getElementById('ttsAudio');

    btn.addEventListener('click', async () => {
      if (!isRecording) {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];

        mediaRecorder.ondataavailable = e => audioChunks.push(e.data);

        mediaRecorder.onstop = async () => {
          const blob = new Blob(audioChunks, { type: 'audio/webm' });
          const formData = new FormData();
          formData.append('audio', blob, 'recording.webm');

          try {
            const res = await fetch('/call-center/', {
              method: 'POST',
              body: formData
            });

            const data = await res.json();

            // ê³µí†µ ì¶œë ¥
            sttTextEl.textContent = `STT í…ìŠ¤íŠ¸: ${data.stt_text || 'ì—†ìŒ'}`;

            // AI ëª¨ë“œ
            if (data.gpt_response) {
              gptResponseEl.textContent = `GPT ì‘ë‹µ: ${data.gpt_response}`;
              gptResponseEl.style.display = 'block';

              if (data.tts_file_path) {
                ttsAudioEl.src = data.tts_file_path;
                ttsAudioEl.style.display = 'block';
                ttsAudioEl.play();
              } else {
                ttsAudioEl.style.display = 'none';
              }

              filteredTextEl.style.display = 'none';
              summaryTextEl.style.display = 'none';
            }
            // Human ëª¨ë“œ
            else {
              gptResponseEl.style.display = 'none';
              ttsAudioEl.style.display = 'none';

              if (data.filtered_question) {
                filteredTextEl.textContent = `í•„í„°ë§ëœ ì§ˆë¬¸: ${data.filtered_question}`;
                filteredTextEl.style.display = 'block';
              } else {
                filteredTextEl.style.display = 'none';
              }

              if (data.summary) {
                summaryTextEl.textContent = `ìš”ì•½: ${data.summary}`;
                summaryTextEl.style.display = 'block';
              } else {
                summaryTextEl.style.display = 'none';
              }
            }

          } catch (err) {
            alert("ì˜¤ë¥˜ ë°œìƒ: " + err);
          }
        };

        mediaRecorder.start();
        isRecording = true;
        btn.textContent = 'Stop Recording';
      } else {
        mediaRecorder.stop();
        isRecording = false;
        btn.textContent = 'Start Recording';
      }
    });
  </script>
</body>
</html>
